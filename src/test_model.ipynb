{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from DL import DataLoader, Batch\n",
    "from SamplePreprocessor import preprocess\n",
    "import decode_beam\n",
    "import os\n",
    "import pathlib\n",
    "import BestPath\n",
    "import Common\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = pathlib.Path(r'C:\\Users\\ddang\\Desktop\\HTR\\model\\model.pt')\n",
    "saved_model = torch.load(PATH)\n",
    "model_ft = saved_model['model']\n",
    "test_batch = saved_model['test_batch']\n",
    "test_labels = saved_model['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSparse(texts):\n",
    "    \"put ground truth texts into sparse tensor for ctc_loss\"\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "    charList = open(FilePaths.fnCharList).read()\n",
    "    # go over all texts\n",
    "    for (batchElement, text) in enumerate(texts):\n",
    "        # convert to string of label (i.e. class-ids)\n",
    "        labelStr = [charList.index(c) for c in text]\n",
    "        # sparse tensor must have size of max. label-string\n",
    "        if len(labelStr) > shape[1]:\n",
    "            shape[1] = len(labelStr)\n",
    "        # put each label into sparse tensor\n",
    "        for (i, label) in enumerate(labelStr):\n",
    "            indices.append([batchElement, i])\n",
    "            values.append(label)\n",
    "\n",
    "    return (indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(phase):\n",
    "    loader = DataLoader(filePath = FilePaths.fnTrain, batchSize = Model.batchSize, imgSize = Model.imgSize, maxTextLen = Model.maxTextLen)\n",
    "    if phase == 'train':\n",
    "        loader.trainSet()\n",
    "    else:\n",
    "        loader.validationSet()\n",
    "    batch, labels, wlabels = [], [], []\n",
    "    batchNumber = 0\n",
    "    while loader.hasNext():\n",
    "#        iterInfo = loader.getIteratorInfo()\n",
    "        batch.append(loader.getNext())\n",
    "        labels.append(toSparse(batch[batchNumber].gtTexts))\n",
    "        wlabels.append(batch[batchNumber].gtTexts)\n",
    "        numBatchElements = len(batch[batchNumber].imgs)\n",
    "#        seqLen.append(Model.maxTextLen * numBatchElements)\n",
    "        batchNumber+= 1\n",
    "    numberOfBatches = batchNumber\n",
    "    charList = loader.charList\n",
    "    return batch, labels, wlabels, numberOfBatches, charList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilePaths:\n",
    "    \"filenames and paths to data\"\n",
    "    fnCharList = (r'C:\\Users\\ddang\\Desktop\\HTR\\model\\charList.txt')\n",
    "    fnAccuracy = (r'CC:\\Users\\ddang\\Desktop\\HTR\\model\\accuracy.txt')\n",
    "    #fnTrain = os.path.join(c, \"User\", \"fastai\", \"courses\", \"dl1\",\"Handwriting recognition project\",\"data\")\n",
    "    #fnTrain = (r'C:\\Users\\User\\fastai\\courses\\dl1\\Handwriting recognition project\\data')\n",
    "    fnTrain = pathlib.Path(r'C:\\Users\\ddang\\Desktop\\HTR\\data')\n",
    "    #print (fnTrain)\n",
    "    fnInfer = (r'C:\\Users\\ddang\\Desktop\\HTR\\data\\test.png')\n",
    "    fnCorpus = (r'C:\\Users\\ddang\\Desktop\\HTR\\data\\corpus.txt')\n",
    "    fnTrainBatch = pathlib.Path(r'C:\\Users\\ddang\\Desktop\\HTR\\data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(mat):\n",
    "    \"calc softmax such that labels per time-step form probability distribution\"\n",
    "    maxT, _ = mat.shape # dim0=t, dim1=c\n",
    "    res = np.zeros(mat.shape)\n",
    "    for t in range(maxT):\n",
    "        y = mat[t, :]\n",
    "        e = np.exp(y)\n",
    "        s = np.sum(e)\n",
    "        if math.isinf(s):\n",
    "            res[t, :] = 0\n",
    "        else:\n",
    "            res[t, :] = e/s\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "batchtrain, labelstrain, wlabelstrain, numberOfBatchestrain, charList = getdata('train')\n",
    "batchval, labelsval, wlabelsval, numberOfBatchesval, charList = getdata('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: \n",
      "['the', 'garte', ',', 'four', 'jclock', 'tomorrow', '?', '\"', 'n', 'why', '?', '\"', 'he', 'enxquired', ',', 'combing', 'his', 'thick', 'I', 'awny', 'hair', '.', '\"', 'To', 'bring', 'me', 'up', 'for', 'tea', ',', 'of', 'ceurse', '.', 'I', 'fust', 'thuaght', ',', ':', ',', 'id', '\\'l\"', 'sep', ',', ',', 'he', 'told', 'her', ',', 'and', 'sueldenly']\n",
      "Correct labels: \n",
      "['the', 'gate', ',', 'four', \"o'clock\", 'tomorrow', '?', '\"', '\"', 'Why', '?', '\"', 'he', 'enquired', ',', 'combing', 'his', 'thick', ',', 'tawny', 'hair', '.', '\"', 'To', 'bring', 'me', 'up', 'for', 'tea', ',', 'of', 'course', '.', 'I', 'just', 'thought', '.', '\"', '\"', 'I', \"'ll\", 'see', ',', '\"', 'he', 'told', 'her', ',', 'and', 'suddenly']\n",
      "Batch Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "#print out predicted labels and labels\n",
    "test_batch0 = batchval[2].imgs\n",
    "test_labels0 = wlabelsval[2]\n",
    "out = model_ft(test_batch0)\n",
    "out = out.squeeze(3)\n",
    "out2 = out.permute(0,2,1)\n",
    "outText = []\n",
    "loader = DataLoader(filePath = FilePaths.fnTrain, batchSize = Model.batchSize, imgSize = Model.imgSize, maxTextLen = Model.maxTextLen)\n",
    "charList = loader.charList\n",
    "accuracy = 0\n",
    "for i in range (out2.shape[0]):\n",
    "    softmaxOut = softmax(out2[i].cpu().detach().numpy())\n",
    "    outText.append(BestPath.ctcBestPath(softmaxOut, charList))\n",
    "    if outText[i] != \" \":\n",
    "        outText[i] = outText[i].replace(\" \",\"\")\n",
    "    if outText[i] == test_labels0[i]:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy/50\n",
    "print (\"Predicted labels: \")\n",
    "print (outText)\n",
    "print (\"Correct labels: \")\n",
    "print (test_labels0)\n",
    "print (\"Batch Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display processed image\n",
    "stack0 = test_batch0[0]\n",
    "stack1 = test_batch0[10]\n",
    "stack2 = test_batch0[20]\n",
    "stack3 = test_batch0[30]\n",
    "stack4 = test_batch0[40]\n",
    "for i in range (9):\n",
    "    stack0 = np.vstack((stack0,test_batch0[i+1]))\n",
    "    stack1 = np.vstack((stack1,test_batch0[i+11]))\n",
    "    stack2 = np.vstack((stack2,test_batch0[i+21]))\n",
    "    stack3 = np.vstack((stack3,test_batch0[i+31]))\n",
    "    stack4 = np.vstack((stack4,test_batch0[i+41]))\n",
    "stack0_out = stack0.transpose().astype(np.uint8)\n",
    "stack1_out = stack1.transpose().astype(np.uint8)\n",
    "stack2_out = stack2.transpose().astype(np.uint8)\n",
    "stack3_out = stack3.transpose().astype(np.uint8)\n",
    "stack4_out = stack4.transpose().astype(np.uint8)\n",
    "cv2.imshow(' ',stack0_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(' ',stack1_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(' ',stack2_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(' ',stack3_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow(' ',stack4_out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FoOt\n"
     ]
    }
   ],
   "source": [
    "#test a single image\n",
    "test_path = (r'C:\\Users\\ddang\\Desktop\\HTR\\data\\Foot.png')\n",
    "test_img = preprocess(cv2.imread(test_path, cv2.IMREAD_GRAYSCALE), imgSize = Model.imgSize, dataAugmentation = False)\n",
    "test_img_in = np.expand_dims(test_img, axis=0)\n",
    "out = model_ft(test_img_in)\n",
    "out = out.squeeze(3)\n",
    "out2 = out.permute(0,2,1)\n",
    "out2 = out2.squeeze(0)\n",
    "softmaxOut = softmax(out2.cpu().detach().numpy())\n",
    "test_image_out = BestPath.ctcBestPath(softmaxOut, charList)\n",
    "test_image_out = test_image_out.replace(\" \",\"\")\n",
    "print (test_image_out)\n",
    "test_img = test_img.astype(np.uint8)\n",
    "cv2.imshow(' ',test_img.transpose())\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
